# 1.2 Probability Theory

패턴인식에서 중요한 개념 중 하나는 **불확실성\(uncertainty\)** 이다. **확률 이론\(Probability Theory\)** 은 불확실성을 정확하고 양적인 방식으로 측정할 수 있는 일관된 프레임워크를 제공해준다. 또한 **결정 이론\(Decision Theory\)** 와 결합하면 현재 가진 정보내에서 최적의 예측을 내릴수 있도록 도와준다.

이 책에서는 다음 예제로 확률을 소개하려고 한다. **확률변수\(Random Variable\)** $$B$$로 `그림 1.2.1`의 박스를 표현한다. 이 확률변수 $$B$$는 빨간색\($$r$$\)과 파랑색\($$b$$\) 두 가지 경우가 있다. 박스 안에 있는 과일의 종류 또한 확률변수 $$F$$로 표현하며, 사과\($$a$$\)와 오렌지\($$o$$\) 두 가지 경우가 있다.

![1.2.1](https://drive.google.com/uc?id=1hDNVW-rKmCVufQTp8qIsJRTH9jG6-RDM)

시작하기 전에 사건의 발생 횟수를 총 시행횟수로 나눈 값을 어떤 사건\(event\)의 확률로 정의한다. 따라서 다음 사건들의 확률을 정의 할 수 있다\(빨강색 박스를 선택할 확률은 40%, 파랑색은 60%다\).

$$\begin{aligned}p(B=b)&=\dfrac{4}{10} \\ p(B=r)&=\dfrac{6}{10}\end{aligned}$$

위 정의에 따르면, 확률은 항상 0과 1사이의 값을 가진다. 또한, 상호 배타적\(mutually exclusive\)이거나 모든 결과\(outcomes\)를 포함하는 경우, 모든 확률의 합은 1이 되어야 한다.

여기서 잠깐 확률에서 **합의 법칙\(sum rule\)**과 **곱의 법칙\(product rule\)** 알아보고 온다.

![1.2.2](https://drive.google.com/uc?id=1Fev1pOn8NeCpwIPW0VN2xaeLvj8nwbU8)

`그림 1.2.2`에서 $$X$$, $$Y$$ 두 개의 확률변수가 있다. $$X$$는 $$x_i$$값을 취할 수 있고\($$i$$는 $$(1, \cdots, M)$$까지\), $$Y$$는 $$y_j$$값을 취할 수 있다\($$j$$는 $$(1, \cdots, N)$$까지\). 또한, $$X$$와 $$Y$$에서 표본을 추출하는데 총 시도횟수를 $$N$$이라고 한다. 그리고 $$X$$가 $$x_i$$값을 취하고 $$Y$$가 $$y_j$$값을 취했을 때의 시도 갯수를 $$n_{ij}$$ 라고 한다. 이때 확률은 $$p(X=x_i, Y=y_j)$$라고 하며, $$X=x_i, Y=y_j$$의 **결합 확률\(joint probability\)** 이라고 한다.

실제로 임의로 횟수를 지정해서 계산을 해보자.

![1.2.3](https://drive.google.com/uc?id=1h420qxgDvEnuiXodW-HDmEjv9W0tol2z)

```python
np.random.seed(777)
A = np.random.randint(1, 10, size=(3, 5))
fig, ax = plt.subplots(1, 1)
ax.matshow(table, cmap="coolwarm")

for (i, j), z in np.ndenumerate(A):
    ax.text(j, i, f"{z}", ha="center", va="center")
ax.set_xticklabels(np.arange(0, 6))
ax.set_yticklabels(np.arange(0, 4))
ax.set_xlabel("$X$", fontsize=20)
ax.set_ylabel("$Y$", fontsize=20).set_rotation(0)

plt.show()
```

{% tabs %}
{% tab title="Math" %}

$$\tag{1.5} p(X=x_i, Y=y_j) = \dfrac{n_{ij}}{N}$$

{% endtab %}
{% tab title="Python" %}

```python
def joint_probability(i, j, A):
    """
    i: index of x element 
    j: index of y element
    """
    return A[j, i] / A.sum()

# x_1, y_2 --> 5/83
p_x1y2 = joint_probability(0, 1, A)
print(round(p_x1y2, 4))
# 0.0602
```

{% endtab %}
{% endtabs %}

확률변수 $$Y$$에 관계없이 $$X=x_i$$의 시도 횟수를 $$c_i$$, $$X$$에 관계없이 $$Y=y_j$$의 시도 횟수를 $$r_j$$라고 하면, 다음과 같이 표현할 수 있다. 

$$
\begin{aligned}
c_i &= \sum_j n_{ij} \\
r_i &= \sum_i n_{ij}
\end{aligned}
$$

이를 통해 확률의 **합의 법칙\(sum rule\)**을 도출해낼 수 있다. $$p(X=x_i)$$를 **주변 확률\(marginal probability\)**이라고도 한다.

{% tabs %}
{% tab title="Math" %}

$$\tag{1.7} p(X=x_i) = \dfrac{c_{i}}{N} = \sum_j^L p(X=x_i, Y=y_j)$$

{% endtab %}
{% tab title="Python" %}

```python
def marginal_probability(k, A, axis=0):
    """
    k: either index of x element or index of y element
    """
    A_sum = A.sum(axis=axis)
    return A_sum[k] / A_sum.sum()

# x_1 --> (8 + 5 + 1) / 83
p_x1 = marginal_probability(0, A, axis=0)
print(round(p_x1, 4))
# 0.1687
```

{% endtab %}
{% endtabs %}

$$X=x_i$$인 사례들을 고려하여 이중에서 $$Y=y_j$$인 확률, 즉 **조건부 확률\(conditional probability\)** $$p(Y=y_j \vert X=x_i)$$를 구할 수 있다. `그림 1.2.2`에서 분해하면 $$X=x_i$$의 주변 확률(marginal probability)중에서 $$Y=y_j$$가 차지하는 비율로 구할 수 있다.

{% tabs %}
{% tab title="Math" %}

$$\tag{1.8} p(Y=y_j \vert X=x_i) = \dfrac{n_ij}{c_{i}}$$

{% endtab %}
{% tab title="Python" %}

```python
def conditional_probability(i, j, A, axis=0):
    """
    i: index of x element, set axis=0 if it is a condition
    j: index of y element, set axis=1 if it is a condition
    """
    A_sum = A.sum(axis=axis)
    sel_dim = i if axis == 0 else j 
    return A[j, i] / A_sum[sel_dim]

# y_2 | x_1 --> 5 / (8 + 5 + 1)
p_y2_x1 = conditional_probability(0, 1, A, axis=0)
print(round(p_y2_x1, 4))
```
{% endtab %}
{% endtabs %}


수식 1.5, 1.7, 1.8을 결합하면, 확률의 **곱의 법칙\(product rule\)**을 도출해낼 수 있다.

$$
\tag{1.9} \begin{aligned}
p(X=x_i, Y=y_j) &= p(Y=y_j \vert X=x_i)p(X=x_i) \\ 
&= \dfrac{n_{ij}}{N} = \dfrac{n_{ij}}{c_i} \dfrac{c_i}{N}
\end{aligned}
$$

위와 같이 표현은 너무 복잡하니 조금더 간단하게 확률변수의 분포를 표현할 때는 $$p(X)$$, 확률변수가 취할 수 있는 값의 분포을 표현할 때는 $$p(x)$$로 약속한다.

$$
\begin{aligned}
\text{sum rule} && p(X) &= \sum_Y p(X, Y) \\
\text{product rule} && p(X, Y) &= p(Y \vert X)p(X)
\end{aligned}
$$

곱의 대칭성 $$p(X, Y) = p(Y, X)$$으로부터 조건부 확률의 관계식으로 **베이즈 정리\(Bayes' theorem\)**을 도출해낼 수 있다.

$$
\tag{1.12} p(Y \vert X) = \dfrac{p(X\vert)p(Y)}{p(X)}
$$

지금까지 배운 것으로 `그림 1.2.1`의 예시에서 어떤 과일을 선택했는데 그 과일이 오렌지라면, 이 오렌지가 어떤 상자에서 나왔을지를 예측 해볼 수 있다. 

1. 각 상자(확률변수 $$B$$)를 선택했을 때 각각의 과일(확률변수 $$F$$)이 나올 확률은 다음과 같다.

    $$
    \begin{aligned}
    p(F=a \vert B=r) &= 1/4 \\ p(F=o \vert B=r) &= 3/4 \\
    p(F=a \vert B=b) &= 3/4 \\ p(F=o \vert B=b) &= 1/4 \\
    \end{aligned}
    $$
2. 확률의 합의 법칙과 곱의 법칙을 적용하여 오렌지를 고르는 전체 확률을 계산할 수 있다.

    $$
    \begin{aligned}
    p(F=o) &= p(F=o \vert B=r)p(B=r) + p(F=o \vert B=b)p(B=b) \\
    &= \dfrac{3}{4}\times \dfrac{4}{10} + \dfrac{1}{4}\times\dfrac{6}{10} = \dfrac{9}{20}
    \end{aligned}
    $$
3. 베이즈 정리를 활용해 구하고 싶은 문제의 확률을 구한다.

    $$
    \begin{aligned}
    p(B=r \vert F=o) &= \dfrac{p(F=o \vert B=r)p(B=r)}{p(F=o)} = \dfrac{3}{4} \times \dfrac{4}{10} \times \dfrac{20}{9} = \frac{2}{3} \\
    p(B=b \vert F=o) &= 1 - \frac{2}{3} = \frac{1}{3}
    \end{aligned}
    $$

이는 다음과 같이 해석할 수 있다. 어떤 박스를 선택했다는 사건을 가르키는 확률변수 $$B$$의 확률($$p(B)$$)은 **사전 확률\(prior probability\)**이라고 한다. 그 이유는 관심있는 사항인 어떤 과일이 선택 되었는지를 관찰하기 '전'의 확률이기 때문이다. 선택한 과일이 오렌지라는 것을 알게 된다면 베이즈 정리를 활용하여 $$p(B\vert F)$$를 구할 수 있다. 이를 **사후 확률\(posterior probability\)**라고 하며, 그 이유는 사건 $$F$$를 관측한 '후'의 확률이기 때문이다. 

마지막으로 "두 확률변수가 **독립적\(independent\)**이다"라고 하는 것은 두 확률변의 확률의 곱이 결합확률과 같은 경우를 말한다. $$p(X, Y) = p(X)p(Y)$$

## 1.2.1 Probability densities(확률 밀도)

지금까지 이산(descrete) 사건들의 확률을 다뤘는데, 연속적인(continious) 변수의 확률을 알아본다. 실수 확률변수 $$x$$가 $$(x, x+\delta x)$$ 구간의 값을 가지고 확률이 $$p(x) \delta x $$라면, $$p(x)$$는 $$x$$의 **확률 밀도\(probability density\)**라고 한다. 이때 $$x$$가 $$(a, b)$$구간 사이의 값을 가질 확률은 다음과 같다.

$$\tag{1.24} p(x \in (a,b)) = \int_a^b p(x) dx$$

추가로 확률의 정의에 의하여 다음 조건을 만족해야한다.

1. $$p(x) \geq 0$$
2. $$\int_{-\infty}^{\infty} p(x) dx = 1$$

확률 밀도의 최댓값은 어떤 확률변수를 선택하는지에 따라서 달라진다. 예를 들어 $$x=g(y)$$의 변환을 하게 되면, 함수 $$f(x)$$ 는 $$\hat{f}(y) = f(g(y))$$로 바뀐다. $$x$$에 대한 확률 밀도 함수 $$p_x(x)$$와 $$y$$에 대한 확률 밀도 함수 $$p_y(y)$$는 서로 다른 확률 밀도를 가진다. $$(x, x + \delta x)$$범위에 속하는 관찰값은 $$(y, y + \delta y)$$로 변환된다. 이는 비선형 변수 변환시 야코비안 인자(Jacobian Factor)가 따라 붙기 때문이다.

* 관련 내용 참고: [링크](https://simonjisu.github.io/math/2020/03/22/probdensity.html)

확률변수 $$x$$가 $$(-\infty, z)$$ 범위에 속할 확률은 **누적 분포 함수(cumulative distribution function)** 라고 한다.

$$
\tag{1.28} P(z) = \int_{-\infty}^{z} p(x) dx
$$

여기서 $$P'(x) = p(x)$$ 다.

`그림 1.2.4` 에서 확률 밀도 함수(빨강)와 누적 분포 함수(파랑)의 모양을 확인 할 수 있다. 주의 할 점은 확률 밀도는 일정 범위$$\delta x$$ 내에 정의되는 함수다.

![1.2.4](https://drive.google.com/uc?id=1jhPKRSaotcAcg56Zu8Gk4pARzFm0lxbr)

벡터 $$\mathbf{x} = (x_1, x_2, \cdots, x_D)$$로 주어진 다변수인 경우, 똑같이 확률 밀도 $$p(\mathbf{x}) = p(x_1, x_2, \cdots, x_D)$$를 정의할 수 있다. 단변수와 같이 다음 조건을 만족해야한다.

1. $$p(\mathbf{x}) \geq 0$$
2. $$\int_{-\infty}^{\infty} p(\mathbf{x}) d\mathbf{x} = 1$$

만약 확률변수 $$x$$가 이산확률변수인 경우 $$p(x)$$를 **확률 질량 함수\(probability mass function\)**이라고도 한다.

또한, 확률 밀도 함수에 합의 법칙, 곱의 법칙, 베이즈 정리를 활용할 수 있다.

$$\begin{aligned} p(x) &= \int p(x,y) dy \\ p(x, y) &= p(y \vert x) p(x)\end{aligned}$$

## 1.2.2 Expectations and covariances

어떤 확률 분포 $$p(x)$$하에 확률 함수 $$f(x)$$의 평균을 **기댓값\(expectation\)**이라고 하며, $$\Bbb{E}(f)$$라고 표기한다.

* 확률 질량 함수인 경우: $$\Bbb{E}[f] = \sum_x p(x)f(x)$$
* 확률 밀도 함수인 경우: $$\Bbb{E}[f] = \int_x p(x)f(x)dx$$

만약 확률 분포에서 유한한 $$N$$개의 샘플을 추출한거라면, 각 포인트들의 유한한 합산으로 기댓값을 근사(approximate)할 수 있다(차후 11장에서 표본 추출 방법론에서 활용한다).

$$\tag{1.35} \Bbb{E}[f] \simeq \dfrac{1}{N}\sum_{n=1}^N f(x_n)$$

다변수 함수의 기뱃값을 구할 경우에는 어떤 변수에 대해 평균을 내는지를 지정하여 계산할 수 있다. 예시로 $$\Bbb{E}_x[f(x, y)]$$는 함수 $$f(x, y)$$의 평균값을 $$x$$의 분포에 대해 구하라는 의미이며, 최종적으로 $$y$$에 대한 함수가 된다.

또한 조건부 확률처럼 **조건부 기댓값\(conditional expectation\)**도 구할 수 있다.

$$\tag{1.37} \Bbb{E}_x[f\vert y] = \sum_x p(x \vert y) p(x)$$

**분산\(variance\)**은 다음과 같이 정의된다.

$$\tag{1.38} var[f] = \Bbb{E}[(f(x) - \Bbb{E}[f(x)])^2] = \Bbb{E}[f(x)^2] - \Bbb{E}[f(x)]^2$$

**공분산\(covariance\)**은 다음과 같이 정의된다.

$$\tag{1.41} \begin{aligned} cov[x, y] &= \Bbb{E}_{x, y}[(x - \Bbb{E}[x])(y - \Bbb{E}[y])] \\
&= \Bbb{E}_{x, y}[xy] - \Bbb{E}[x]\Bbb{E}[y]\end{aligned}$$

다변수의 경우 다음과 같다.

$$\tag{1.42} \begin{aligned} cov[\mathbf{x}, \mathbf{y}] &= \Bbb{E}_{\mathbf{x}, \mathbf{y}}[(\mathbf{x} - \Bbb{E}[\mathbf{x}])(\mathbf{y}^T - \Bbb{E}[\mathbf{y}^T])] \\
&= \Bbb{E}_{\mathbf{x}, \mathbf{y}}[\mathbf{x}\mathbf{y}^T] - \Bbb{E}[\mathbf{x}]\Bbb{E}[\mathbf{y}^T]\end{aligned}$$

## 1.2.3 Bayesian probabilities

확률에는 두 가지 관점이 있다.

1. **빈도적(frequentist)** 혹은 **고전적(classical)** 관점: 확률을 임의의 반복 가능한 사건의 빈도수
2. **베이지안(Bayesian)** 관점: 불확실성을 정량화하고 증거를 통해 불확실성을 줄여 나가는 것, 불확실성을 나타내는 도구로 확률을 사용.

1.1절의 예제에서 매개변수 $$\mathbf{w}$$를 베이지안 관점을 사용하면, 확률론의 다양한 장치를 활용하여 모델 매개변수의 불확실성을 설명할 수 있다. 첫 데이터를 관찰하기 전의 $$\mathbf{w}$$에 대한 가정을 사전 확률분포 $$p(\mathbf{w})$$로 표현할 수 있다. 그리고 관측된 데이터 $$\mathcal{D} = \{t_1, \cdots, t_N\}$$은 조건부 확률 $$p(\mathcal{D}\vert \mathbf{w})$$로써 작용한다. 데이터 관찰 후 매개변수의 확률 $$p(\mathbf{w}\vert \mathcal{D})$$을 베이지안 정리롤 풀어내면 다음과 같다.

$$\tag{1.43} p(\mathbf{w}\vert \mathcal{D}) = \dfrac{p(\mathcal{D}\vert \mathbf{w})p(\mathbf{w})}{p(\mathcal{D})}$$

수식 1.43 우측의 $$p(\mathcal{D}\vert \mathbf{w})$$는 **가능도 함수(likelihood function)**라고 하며 이는 매개변수 벡터 $$\mathbf{w}$$의 함수로 볼 수 있다. 가능도 함수의 의미는 주어진 $$\mathbf{w}$$에 대해 관측된 데이터 집합이 얼마나 '이렇게 나타날 가능성이 있는가'를 표현한다. 가능도 함수는 $$\mathbf{w}$$에 대한 확률분포가 아니기 때문에 이를 적분해도 1이 될 필요가 없다.

빈도적 관점과 베이지안 관점의 차이는 가능도 함수에서 나타난다. 

**빈도적 관점:** 
* $$\mathbf{w}$$가 고정된 매개변수이고, 어떤 형태의 '추정자(estimator)' 데이터 $$\mathcal{D}$$의 분포를 고려하면서 오류를 줄이는 방향으로 매개변수값이 결정된다. 
* 보통 estimator로 **최대 가능도\(maximum likelihood\)**를 사용하며, $$\mathbf{w}$$가 가능도 함수 $$p(\mathcal{D}\vert \mathbf{w})$$를 최대화하는 값으로 선택된다. 보통 음의 로그 가능도(negative log likelihood)를 **오차함수(error function)**로 설정하여 추정한다(단조 감소하기 때문에 가능도의 최댓값을 찾는 것은 곧 오차함수의 최솟값을 찾는 것과 동일). 
* 오차를 측정하는 방법중 하나는 **부트스트랩\(bootstrap\)**인데, 데이터 집합에서 여러번 중복 가능하게 임의로 추출하여 여러개의 데이터 집합으로 만든 후, 여러번 매개변수를 추정하여 추정값의 통계적 정확도를 판단하는 방법이다.

**베이지안 관점:**
* 많은 경우 중 하나의 데이터 집합 $$\mathcal{D}$$이 관측된 것일 뿐이며, 매개변수 $$\mathbf{w}$$의 불확실성은 $$\mathbf{w}$$의 분포로 표현한다. 
* 장점중 하나는 사전 지식을 추론 과정에 자연스럽게 포함시킬 수 있다는 것이다. 이는 과도한 결론이 나오지 않게 방지한다. 예: 동전을 세번 던졌는데 모두 앞면인 경우 빈도적 관점에서 확률은 1이다.
* 몇 가지 비판중 하나는 사전 확률의 선택에 따라 결론이 나기 때문에 추론 과정에 주관이 포함될 수밖에 없다. 이를 보정하기 위해 무정보적(noninformative) 사전 분포를 사용하는 경우도 있다.
* 베이지안 절차를 완전히 활용하기 위해서는 전체 매개변수 공간에 대한 marginalize(주변화: 합 또는 적분)이 필요하다. 몬테 카를로 방법론과 컴퓨터 연산 속도, 메모리의 발전으로 사용할 수 있게 되었다.

## 1.2.4 The Gaussian distribution

2장에서 다양한 확률 분포를 살펴보기 전에 자주 보는 **가우시안 분포(Gaussian distribution)** 또는 **정규 분포(normal distribution)**를 먼저 살펴본다.

단일 실수 확률변수 $$x$$에 대해서 가우시안 분포는 다음과 같다.

$$\tag{1.46} \mathcal{N}(x \vert \mu, \sigma^2) = \dfrac{1}{(2\pi \sigma^2)^{\frac{1}{2}}} \exp \Big\{ - \dfrac{1}{2\sigma^2} (x - \mu)^2 \Big\}$$

* $$\mu$$는 평균(mean), $$\sigma^2$$ 분산(variance), $$\sigma$$는 표준편차(standard deviation)라고 하고, 분산의 역인 $$\beta = 1/\sigma^2$$는 정밀도(precision)라고 한다. 
* 가우시안 분포는 확률 분포의 특성을 만족한다.

    $$\begin{aligned} \mathcal{N}(x \vert \mu, \sigma^2) > 0 \\ \int_{-\infty}^{\infty} \mathcal{N}(x \vert \mu, \sigma^2) dx = 1 \end{aligned}$$

가우시안 분포를 따르는 임의의 $$x$$에 대해 함수의 기댓값을 구하면 다음과 같다.

$$\tag{1.49} \Bbb{E}[x] = \int_{-\infty}^{\infty} \mathcal{N}(x \vert \mu, \sigma^2)x dx = \mu$$

분산은 다음과 같다. 

$$\begin{aligned} 
var[x] &= \Bbb{E}[x^2] - \Bbb{E}[x]^2 \\
&= \int_{-\infty}^{\infty} \mathcal{N}(x \vert \mu, \sigma^2)x^2 dx - \mu^2 \\
&= \mu^2 + \sigma^2 - \mu^2  \\
& = \sigma^2
\end{aligned}$$

이제 연속 변수 D차원 벡터 $$\mathbf{x} = (x_1, x_2, \cdots x_D)^T$$로 확장한다. $$\mathbf{x}$$에 대한 가우시안 분포는 다음과 같다.

$$\tag{1.52} \mathcal{N}(\mathbf{x} \vert \mathbf{\mu}, \mathbf{\sigma}^2) = \dfrac{1}{(2\pi)^{D / 2}} \dfrac{1}{\vert \Sigma \vert^{1/2}}  \exp \Big\{ -\dfrac{1}{2}(\mathbf{x} - \mathbf{\mu})^T \Sigma^{-1} (\mathbf{x} - \mathbf{\mu}) \Big\}$$

* D차원 벡터 $$\mathbf{\mu}$$는 평균값, $$D \times D$$행렬 $$\Sigma$$는 공분산이라고 한다. $$\vert \Sigma \vert$$는 $$\Sigma$$의 행렬식이다.

다시 단일 실수 확률변수로 돌아오면, 관측 데이터 $$X = (x_1, x_2, \cdots, x_N)^T$$에서 각 변수 $$x_n$$는 평균값 $$\mu$$, 분산 $$\sigma^2$$를 따르는 가우시안 분포에서 독립적으로 추출한다고 가정한다. 이를 **독립적이고 동일하게 분포(independent and identically distributed - i.i.d)** 되었다고 한다. 따라서 $$X$$는 i.i.d이기 때문에 $$\mu, \sigma^2$$가 주어졌을 때 조건부 확률은 다음과 같다.

$$\tag{1.53} p(X \vert \mu, \sigma^2) = \prod_{n=1}^{N} \mathcal{N}(x_n \vert \mu, \sigma^2)$$

수식 1.53은 $$\mu, \sigma^2$$에 대한 **가능도 함수(likelihood function)**에 해당한다. 관측된 데이터 집합($$X$$)을 바탕으로 매개변수 $$\mu, \sigma^2$$를 결정짓는 방법 중 하나는 가능도 함수를 최대화하는 매개변수를 찾는 것이다. 이는 양변에 단조함수인 $$\log$$를 취하여 최댓값을 찾는 것과 동일하다. 

$$\tag{1.54} \ln p(X\vert \mu, \sigma^2) = - \dfrac{1}{2\sigma^2} \sum_{n=1}^N(x_n - \mu)^2 - \dfrac{N}{2} \ln \sigma^2 - \dfrac{N}{2} \ln (2 \pi)$$

$$\mu$$에 대해 수식 1.54의 최댓값을 찾으면, 관찬값들의 평균인 **표본 평균(sample mean)**과 **표본 분산(sample variance)**은 다음과 같다. 

$$\begin{aligned} \mu_{MLE} &= \dfrac{1}{N}\sum_{n=1}^N x_n \\
\sigma_{MLE}^2 &= \dfrac{1}{N}\sum_{n=1}^N (x_n - \mu_{MLE})^2 \end{aligned}$$

그러나 이렇게 구하는 것은 분포의 분산을 과소평가하게 된다. 위 수식들의 기댓값을 구하면 다음과 같다.

$$\begin{aligned} \Bbb{E}[\mu_{MLE}] &= \mu \\
\Bbb{E}[\sigma_{MLE}^2] &= \dfrac{N-1}{N} \sigma^2 \end{aligned}$$

즉, 실제 분산은 $$\dfrac{N-1}{N}$$ 만큼 작아져 있다는 것을 알 수 있으며, 이렇게 차이가 나는 것을 **편향(bias)** 이라는 현상이다. 따라서 실제 분포의 분산($$\tilde{\sigma}$$)을 추정하려면 다음과 같다.

$$\tag{1.59} \tilde{\sigma}^2 = \dfrac{N}{N-1} \sigma_{MLE}^2 = \dfrac{1}{N-1} \sum_{n=1}^N (x_n - \mu_{MLE})^2$$

수식 1.59에서 알 수있는 것은 데이터 개수($$N$$)가 클 수록 최대 가능도로 구한 해(solution)에서 편향치는 점점 줄어든다. 복잡한 모델일 수록 최대 가능도 방법과 연관된 편향 문제는 심각해진다. 또한, 이 편향 문제는 과적합 문제의 근본적인 원인에 해당한다.
