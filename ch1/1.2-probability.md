# 1.2 Probability Theory

패턴인식에서 중요한 개념 중 하나는 **불확실성\(uncertainty\)** 이다. **확률 이론\(Probability Theory\)** 은 불확실성을 정확하고 양적인 방식으로 측정할 수 있는 일관된 프레임워크를 제공해준다. 또한 **결정 이론\(Decision Theory\)** 와 결합하면 현재 가진 정보내에서 최적의 예측을 내릴수 있도록 도와준다.

이 책에서는 다음 예제로 확률을 소개하려고 한다. 확률 변수\(Random Variable\) $$B$$로 `그림 1.2.1`의 박스를 표현한다. 이 확률 변수 $$B$$는 빨간색\($$r$$\)과 파랑색\($$b$$\) 두 가지 경우가 있다. 박스 안에 있는 과일의 종류 또한 확률 변수 $$F$$로 표현하며, 사과\($$a$$\)와 오렌지\($$o$$\) 두 가지 경우가 있다.

![1.2.1](https://drive.google.com/uc?id=1hDNVW-rKmCVufQTp8qIsJRTH9jG6-RDM)

시작하기 전에 사건의 발생 횟수를 총 시행횟수로 나눈 값을 어떤 사건\(event\)의 확률로 정의 한다. 따라서 다음 사건들의 확률을 정의 할 수 있다\(빨강색 박스를 선택할 확률은 40%, 파랑색은 60%다\).

$$\begin{aligned}p(B=b)&=\dfrac{4}{10} \\ p(B=r)&=\dfrac{6}{10}\end{aligned}$$

위 정의에 따르면, 확률은 항상 0과 1사이의 값을 가진다. 또한, 상호 배타적\(mutually exclusive\)이거나 모든 결과\(outcomes\)를 포함하는 경우, 모든 확률의 합은 1이 되어야 한다.

여기서 잠깐 확률에서 **합의 법칙\(sum rule\)**과 **곱의 법칙\(product rule\)** 알아보고 온다.

![1.2.2](https://drive.google.com/uc?id=1Fev1pOn8NeCpwIPW0VN2xaeLvj8nwbU8)

`그림 1.2.2`에서 $$X$$, $$Y$$ 두 개의 확률 변수가 있다. $$X$$는 $$x_i$$값을 취할 수 있고\($$i$$는 $$(1, \cdots, M)$$까지\), $$Y$$는 $$y_j$$값을 취할 수 있다\($$j$$는 $$(1, \cdots, N)$$까지\). 또한, $$X$$와 $$Y$$에서 표본을 추출하는데 총 시도횟수를 $$N$$이라고 한다. 그리고 $$X$$가 $$x_i$$값을 취하고 $$Y$$가 $$y_j$$값을 취했을 때의 시도 갯수를 $$n_{ij}$$ 라고 한다. 이때 확률은 $$p(X=x_i, Y=y_j)$$라고 하며, $$X=x_i, Y=y_j$$의 **결합 확률\(joint probability\)** 이라고 한다.

실제로 임의로 횟수를 지정해서 계산을 해보자.

![1.2.3](https://drive.google.com/uc?id=1h420qxgDvEnuiXodW-HDmEjv9W0tol2z)

```python
np.random.seed(777)
A = np.random.randint(1, 10, size=(3, 5))
fig, ax = plt.subplots(1, 1)
ax.matshow(table, cmap="coolwarm")

for (i, j), z in np.ndenumerate(A):
    ax.text(j, i, f"{z}", ha="center", va="center")
ax.set_xticklabels(np.arange(0, 6))
ax.set_yticklabels(np.arange(0, 4))
ax.set_xlabel("$X$", fontsize=20)
ax.set_ylabel("$Y$", fontsize=20).set_rotation(0)

plt.show()
```

{% tabs %}
{% tab title="Math" %}

$$\tag{1.5} p(X=x_i, Y=y_j) = \dfrac{n_{ij}}{N}$$

{% endtab %}
{% tab title="Python" %}

```python
def joint_probability(i, j, A):
    """
    i: index of x element 
    j: index of y element
    """
    return A[j, i] / A.sum()

# x_1, y_2 --> 5/83
p_x1y2 = joint_probability(0, 1, A)
print(round(p_x1y2, 4))
# 0.0602
```

{% endtab %}
{% endtabs %}

확률 변수 $$Y$$에 관계없이 $$X=x_i$$의 시도 횟수를 $$c_i$$, $$X$$에 관계없이 $$Y=y_j$$의 시도 횟수를 $$r_j$$라고 하면, 다음과 같이 표현할 수 있다. 

$$
\begin{aligned}
c_i &= \sum_j n_{ij} \\
r_i &= \sum_i n_{ij}
\end{aligned}
$$

이를 통해 확률의 **합의 법칙\(sum rule\)**을 도출해낼 수 있다. $$p(X=x_i)$$를 **주변 확률\(marginal probability\)**이라고도 한다.

{% tabs %}
{% tab title="Math" %}

$$\tag{1.7} p(X=x_i) = \dfrac{c_{i}}{N} = \sum_j^L p(X=x_i, Y=y_j)$$

{% endtab %}
{% tab title="Python" %}

```python
def marginal_probability(k, A, axis=0):
    """
    k: either index of x element or index of y element
    """
    A_sum = A.sum(axis=axis)
    return A_sum[k] / A_sum.sum()

# x_1 --> (8 + 5 + 1) / 83
p_x1 = marginal_probability(0, A, axis=0)
print(round(p_x1, 4))
# 0.1687
```

{% endtab %}
{% endtabs %}

$$X=x_i$$인 사례들을 고려하여 이중에서 $$Y=y_j$$인 확률, 즉 **조건부 확률\(conditional probability\)** $$p(Y=y_j \vert X=x_i)$$를 구할 수 있다. `그림 1.2.2`에서 분해하면 $$X=x_i$$의 주변 확률(marginal probability)중에서 $$Y=y_j$$가 차지하는 비율로 구할 수 있다.

{% tabs %}
{% tab title="Math" %}

$$\tag{1.8} p(Y=y_j \vert X=x_i) &= \dfrac{n_ij}{c_{i}}$$

{% endtab %}
{% tab title="Python" %}

```python
def conditional_probability(i, j, A, axis=0):
    """
    i: index of x element, set axis=0 if it is a condition
    j: index of y element, set axis=1 if it is a condition
    """
    A_sum = A.sum(axis=axis)
    sel_dim = i if axis == 0 else j 
    return A[j, i] / A_sum[sel_dim]

# y_2 | x_1 --> 5 / (8 + 5 + 1)
p_y2_x1 = conditional_probability(0, 1, A, axis=0)
print(round(p_y2_x1, 4))
```
{% endtab %}
{% endtabs %}


수식 1~3을 결합하면, 확률의 **곱의 법칙\(product rul\)**을 도출해낼 수 있다.

$$
\tag{1.9} \begin{aligned}
p(X=x_i, Y=y_j) &= p(Y=y_j \vert X=x_i)p(X=x_i) \\ 
&= \dfrac{n_{ij}}{N} = \dfrac{n_{ij}}{c_i} \dfrac{c_i}{N}
\end{aligned}
$$

위와 같이 표현은 너무 복잡하니 조금더 간단하게 확률 변수의 분포를 표현할 때는 $$p(X)$$, 확률 변수가 취할 수 있는 값의 분포을 표현할 때는 $$p(x)$$로 약속한다.

$$
\begin{aligned}
\text{sum rule} && p(X) &= \sum_Y p(X, Y) \\
\text{product rule} && p(X, Y) &= p(Y \vert X)p(X)
\end{aligned}
$$

곱의 대칭성 $$p(X, Y) = p(Y, X)$$으로부터 조건부 확률의 관계식으로 **베이즈 정리\(Bayes' theorem\)**을 도출해낼 수 있다.

$$
\tag{1.12} p(Y \vert X) = \dfrac{p(X\vert)p(Y)}{p(X)}
$$

지금까지 배운 것으로 `그림 1.2.1`의 예시에서 어떤 과일을 선택했는데 그 과일이 오렌지라면, 이 오렌지가 어떤 상자에서 나왔을지를 예측 해볼 수 있다. 

1. 각 상자(확률변수 $$B$$)를 선택했을 때 각각의 과일(확률변수 $$F$$)이 나올 확률은 다음과 같다.

    $$
    \begin{aligned}
    p(F=a \vert B=r) &= 1/4 \\ p(F=o \vert B=r) &= 3/4 \\
    p(F=a \vert B=b) &= 3/4 \\ p(F=o \vert B=b) &= 1/4 \\
    \end{aligned}
    $$
2. 확률의 합의 법칙과 곱의 법칙을 적용하여 오렌지를 고르는 전체 확률을 계산할 수 있다.

    $$
    \begin{aligned}
    p(F=o) &= p(F=o \vert B=r)p(B=r) + p(F=o \vert B=b)p(B=b) \\
    &= \dfrac{3}{4}\times \dfrac{4}{10} + \dfrac{1}{4}\times\dfrac{6}{10} = \dfrac{9}{20}
    \end{aligned}
    $$
3. 베이즈 정리를 활용해 구하고 싶은 문제의 확률을 구한다.

    $$
    \begin{aligned}
    p(B=r \vert F=o) &= \dfrac{p(F=o \vert B=r)p(B=r)}{p(F=o)} = \dfrac{3}{4} \times \dfrac{4}{10} \times \dfrac{20}{9} = \frac{2}{3} \\
    p(B=b \vert F=o) &= 1 - \frac{2}{3} = \frac{1}{3}
    \end{aligned}
    $$

이는 다음과 같이 해석할 수 있다. 어떤 박스를 선택했다는 사건을 가르키는 확률변수 $$B$$의 확률($$p(B)$$)은 **사전 확률\(prior probability\)**이라고 한다. 그 이유는 관심있는 사항인 어떤 과일이 선택 되었는지를 관찰하기 '전'의 확률이기 때문이다. 선택한 과일이 오렌지라는 것을 알게 된다면 베이즈 정리를 활용하여 $$p(B\vert F)$$를 구할 수 있다. 이를 **사후 확률\(posterior probability\)**라고 하며, 그 이유는 사건 $$F$$를 관측한 '후'의 확률이기 때문이다. 

마지막으로 "두 확률변수가 **독립적\(independent\)**이다"라고 하는 것은 두 확률변의 확률의 곱이 결합확률과 같은 경우를 말한다. $$p(X, Y) = p(X)p(Y)$$

## 1.2.1 Probability densities(확률 밀도)

지금까지 이산(descrete) 사건들의 확률을 다뤘는데, 연속적인(continious) 변수의 확률을 알아본다. 실수 확률 변수 $$x$$가 $$(x, x+\delta x)$$ 구간의 값을 가지고 확률이 $$p(x) \delta x $$라면, $$p(x)$$의 $$x$$의 **확률 밀도\(probability density\)**라고 한다. 이때 $$x$$가 $$(a, b)$$구간 사이의 값을 가질 확률은 다음과 같다.

$$\tag{1.24} p(x \in (a,b)) = \int_a^b p(x) dx$$

추가로 확률의 정의에 의하여 다음 조건을 만족해야한다.

1. $$p(x) \geq 0$$
2. \int_{-\infty}^{\infty} p(x) dx = 1

확률 밀도의 최댓값은 어떤 확률 변수를 선택하는지에 따라서 달라진다. 예를 들어 $$x=g(y)$$의 변환을 하게 되면, 함수 $$f(x)$$ 는 $$\hat{f}(y) = f(g(y))$$로 바뀐다. $$x$$에 대한 확률 밀도 함수 $$p_x(x)$$와 $$y$$에 대한 확률 밀도 함수 $$p_y(y)$$는 서로 다른 확률 밀도를 가진다. $$(x, x + \delta x)$$범위에 속하는 관찰값은 $$(y, y + \delta y)$$로 변환된다. 이는 비선형 변수 변환시 야코비안 인자(Jacobian Factor)가 따라 붙기 때문이다.

* 관련 내용 참고: [링크](https://simonjisu.github.io/math/2020/03/22/probdensity.html)

확률변수 $$x$$가 $$(-\infty, z)$$ 범위에 속할 확률은 **누적 분포 함수(cumulative distribution function)** 라고 한다.

$$
\tag{1.28} P(z) = \int_{-\infty}^{z} p(x) dx
$$

여기서 $$P'(x) = p(x)$$ 다.

`그림 1.2.4` 에서 확률 밀도 함수(빨강)와 누적 분포 함수(파랑)의 모양을 확인 할 수 있다. 주의 할 것은 확률 밀도는 일정 범위$$\delta x$$ 내에 정의되는 함수라는 것이다.

![1.2.4](https://drive.google.com/uc?id=1jhPKRSaotcAcg56Zu8Gk4pARzFm0lxbr)

벡터 $$\mathbf{x} = (x_1, x_2, \cdots, x_D)$$로 주어진 다변수인 경우, 똑같이 확률 밀도 $$p(\mathbf{x}) = p(x_1, x_2, \cdots, x_D)$$를 정의할 수 있다. 단변수와 같이 다음 조건을 만족해야한다.

1. $$p(\mathbf{x}) \geq 0$$
2. $$\int_{-\infty}^{\infty} p(\mathbf{x}) d\mathbf{x} = 1$$

확률변수 $$x$$가 이산확률 변수인 경우 $$p(x)$$를 **확률 질량 함수\(probability mass function\)**이라고도 한다.

또한, 확률 밀도 함수에 합의 법칙, 곱의 법칙, 베이즈 정리를 활용할 수 있다.

## 1.2.2 Expectations and covariances

어떤 확률 분포 $$p(x)$$하에 확률 함수 $$f(x)$$의 평균을 **기댓값\(expectation\)**이라고 하며, $$\Bbb{E}(f)$$라고 표기한다.

* 확률 질량 함수인 경우: $$\Bbb{E}[f] = \sum_x p(x)f(x)$$
* 확률 밀도 함수인 경우: $$\Bbb{E}[f] = \int_x p(x)f(x)dx$$

만약 확률 분포에서 유한한 $$N$$개의 샘플을 추출한거라면, 각 포인트들의 유한한 합산으로 기댓값을 근사(approximate)할 수 있다(차후 11장에서 표본 추출 방법론에서 활용한다).

$$\tag{1.35} \Bbb{E}[f] \simeq \dfrac{1}{N}\sum_{n=1}^N f(x_n)$$

다변수 함수의 기뱃값을 구할 경우에는 어떤 변수에 대해 평균을 내는지를 지정하여 계산할 수 있다. 예시로 $$\Bbb{E}_x[f(x, y)]$$는 함수 $$f(x, y)$$의 평균값을 $$x$$의 분포에 대해 구하라는 의미이며, 최종적으로 $$y$$에 대한 함수가 된다.

또한 조건부 확률처럼 **조건부 기댓값\(conditional expectation\)**도 구할 수 있다.

$$\tag{1.37} \Bbb{E}_x[f\vert y] = \sum_x p(x \vert y) p(x)$$

**분산\(variance\)**은 다음과 같이 정의된다.

$$\tag{1.38} var[f] = \Bbb{E}[(f(x) - \Bbb{E}[f(x)])^2] = \Bbb{E}[f(x)^2] - \Bbb{E}[f(x)]^2$$

**공분산\(covariance\)**은 다음과 같이 정의된다.

$$\tag{1.41} \begin{aligned} cov[x, y] &= \Bbb{E}_{x, y}[(x - \Bbb{E}[x])(y - \Bbb{E}[y])] \\
&= \Bbb{E}_{x, y}[xy] - \Bbb{E}[x]\Bbb{E}[y]\end{aligned}$$

다변수의 경우 다음과 같다.

$$\tag{1.42} \begin{aligned} cov[\mathbf{x}, \mathbf{y}] &= \Bbb{E}_{\mathbf{x}, \mathbf{y}}[(\mathbf{x} - \Bbb{E}[\mathbf{x}])(\mathbf{y}^T - \Bbb{E}[\mathbf{y}^T])] \\
&= \Bbb{E}_{\mathbf{x}, \mathbf{y}}[\mathbf{x}\mathbf{y}^T] - \Bbb{E}[\mathbf{x}]\Bbb{E}[\mathbf{y}^T]\end{aligned}$$